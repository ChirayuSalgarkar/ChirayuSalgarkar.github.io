\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Policy Gradient}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Policy Objective functions}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Finite Difference Policy Gradient}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Monte-Carlo Policy Gradient}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Derivation of the Score Function}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why This is Useful}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Conclusion}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Softmax Policy with Linear Features}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Score Function}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Explanation}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gaussian Policy}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Log-Probability of a Gaussian Policy}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Score Function for a Gaussian Policy}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}One-step MDPs}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{One-Step MDPs}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Policy Optimization in One-Step MDPs}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{One-Step MDPs}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Objective Function \( J(\theta ) \) in One-Step MDPs}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Multi-Step MDPs}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Policy Objective \( J(\theta ) \)}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Monte Carlo Policy Gradient (REINFORCE)}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Stochastic Gradient Ascent}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Actor-Critic Policy Gradient}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reducing Variance with a Critic}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Approximate Policy Gradient}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Summary}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Problems}{8}{}\protected@file@percent }
\gdef \@abspage@last{10}
