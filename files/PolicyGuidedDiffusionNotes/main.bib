@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{hambro2022dungeons,
  title={Dungeons and Data: A Large-Scale NetHack Dataset},
  author={Hambro, Eric and Raileanu, Roberta and Rothermel, Danielle and Mella, Vegard and Rockt{\"a}schel, Tim and K{\"u}ttler, Heinrich and Murray, Naila},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24864--24878},
  year={2022}
}

@article{hafner2021benchmarking,
  title={Benchmarking the spectrum of agent capabilities},
  author={Hafner, Danijar},
  journal={arXiv preprint arXiv:2109.06780},
  year={2021}
}

@article{kostrikov2021offline,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@misc{sims2024edgeofreach,
      title={The Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning}, 
      author={Anya Sims and Cong Lu and Yee Whye Teh},
      year={2024},
      eprint={2402.12527},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{chua2018deep,
      title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models}, 
      author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
      year={2018},
      eprint={1805.12114},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{minari,
  author={{Farama Foundation}},
  title={Minari v0.4.1},
  year={2023},
  url={https://github.com/Farama-Foundation/Minari/releases/tag/v0.4.1},
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{hafner2023mastering,
  title={Mastering diverse domains through world models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104},
  year={2023}
}

@book{Sutton1998,
  added-at = {2019-07-13T10:11:53.000+0200},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  biburl = {https://www.bibsonomy.org/bibtex/2f46601cf8b13d39d1378af0d79438b12/lanteunis},
  edition = {Second},
  interhash = {ac6b144aaec1819919a2fba9f705c852},
  intrahash = {f46601cf8b13d39d1378af0d79438b12},
  keywords = {},
  publisher = {The MIT Press},
  timestamp = {2019-07-13T10:11:53.000+0200},
  title = {Reinforcement Learning: An Introduction},
  url = {http://incompleteideas.net/book/the-book-2nd.html},
  year = {2018 }
}

@article{he2023diffusion,
  title={Diffusion Model is an Effective Planner and Data Synthesizer for Multi-Task Reinforcement Learning},
  author={He, Haoran and Bai, Chenjia and Xu, Kang and Yang, Zhuoran and Zhang, Weinan and Wang, Dong and Zhao, Bin and Li, Xuelong},
  journal={arXiv preprint arXiv:2305.18459},
  year={2023}
}

@misc{azizi2023synthetic,
      title={Synthetic Data from Diffusion Models Improves ImageNet Classification}, 
      author={Shekoofeh Azizi and Simon Kornblith and Chitwan Saharia and Mohammad Norouzi and David J. Fleet},
      year={2023},
      eprint={2304.08466},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Kirk_2023,
   title={A Survey of Zero-shot Generalisation in Deep Reinforcement Learning},
   volume={76},
   ISSN={1076-9757},
   url={http://dx.doi.org/10.1613/jair.1.14174},
   DOI={10.1613/jair.1.14174},
   journal={Journal of Artificial Intelligence Research},
   publisher={AI Access Foundation},
   author={Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rocktäschel, Tim},
   year={2023},
   month=jan, pages={201–264} }



@InProceedings{augwm,
  title = 	 {Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment},
  author =       {Ball, Philip J and Lu, Cong and Parker-Holder, Jack and Roberts, Stephen},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {619--629},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
}


@inproceedings{fujimoto2021minimalist,
	title={A Minimalist Approach to Offline Reinforcement Learning},
	author={Scott Fujimoto and Shixiang Shane Gu},
	booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
	year={2021},
}

@InProceedings{bcq,
  title = 	 {Off-Policy Deep Reinforcement Learning without Exploration},
  author =       {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2052--2062},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/fujimoto19a/fujimoto19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/fujimoto19a.html},
  abstract = 	 {Many practical applications of reinforcement learning constrain agents to learn from a fixed batch of data which has already been gathered, without offering further possibility for data collection. In this paper, we demonstrate that due to errors introduced by extrapolation, standard off-policy deep reinforcement learning algorithms, such as DQN and DDPG, are incapable of learning with data uncorrelated to the distribution under the current policy, making them ineffective for this fixed batch setting. We introduce a novel class of off-policy algorithms, batch-constrained reinforcement learning, which restricts the action space in order to force the agent towards behaving close to on-policy with respect to a subset of the given data. We present the first continuous control deep reinforcement learning algorithm which can learn effectively from arbitrary, fixed batch data, and empirically demonstrate the quality of its behavior in several tasks.}
}


@inproceedings{
lu2022revisiting,
title={Revisiting Design Choices in Offline Model Based Reinforcement Learning},
author={Cong Lu and Philip Ball and Jack Parker-Holder and Michael Osborne and Stephen J. Roberts},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=zz9hXVhf40}
}

@inproceedings{
rambo,
title={{RAMBO}-{RL}: Robust Adversarial Model-Based Offline Reinforcement Learning},
author={Marc Rigter and Bruno Lacerda and Nick Hawes},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=nrksGSRT7kX}
}

@inproceedings{janner2019mbpo,
  author = {Michael Janner and Justin Fu and Marvin Zhang and Sergey Levine},
  title = {When to Trust Your Model: Model-Based Policy Optimization},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2019}
}

@inproceedings{10.5555/645529.658134,
author = {Precup, Doina and Sutton, Richard S. and Singh, Satinder P.},
title = {Eligibility Traces for Off-Policy Policy Evaluation},
year = {2000},
isbn = {1558607072},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
pages = {759–766},
numpages = {8},
series = {ICML '00}
}

@inproceedings{
ajay2023is,
title={Is Conditional Generative Modeling all you need for Decision Making?},
author={Anurag Ajay and Yilun Du and Abhi Gupta and Joshua B. Tenenbaum and Tommi S. Jaakkola and Pulkit Agrawal},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=sP1fo2K9DFG}
}

@misc{wang2023diffusion,
      title={Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning}, 
      author={Zhendong Wang and Jonathan J Hunt and Mingyuan Zhou},
      year={2023},
      eprint={2208.06193},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{rigter2023world,
      title={World Models via Policy-Guided Trajectory Diffusion}, 
      author={Marc Rigter and Jun Yamada and Ingmar Posner},
      year={2023},
      eprint={2312.08533},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{janner2022diffuser,
  title = {Planning with Diffusion for Flexible Behavior Synthesis},
  author = {Michael Janner and Yilun Du and Joshua Tenenbaum and Sergey Levine},
  booktitle = {International Conference on Machine Learning},
  year = {2022},
}

@inproceedings{mopo,
 author = {Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {14129--14142},
 publisher = {Curran Associates, Inc.},
 title = {MOPO: Model-based Offline Policy Optimization},
 url = {https://proceedings.neurips.cc/paper/2020/file/a322852ce0df73e204b7e67cbbef0d0a-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{ddpm,
 author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {6840--6851},
 publisher = {Curran Associates, Inc.},
 title = {Denoising Diffusion Probabilistic Models},
 url = {https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{hafner2020mastering,
  title={Mastering atari with discrete world models},
  author={Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba, Jimmy},
  journal={arXiv preprint arXiv:2010.02193},
  year={2020}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@article{an2021uncertainty,
  title={Uncertainty-based offline reinforcement learning with diversified q-ensemble},
  author={An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7436--7447},
  year={2021}
}

@InProceedings{pmlr-v37-sohl-dickstein15,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2256--2265},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = 	 {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@article{hyvarinen2005estimation,
  title={Estimation of non-normalized statistical models by score matching.},
  author={Hyv{\"a}rinen, Aapo and Dayan, Peter},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={4},
  year={2005}
}

@inproceedings{janner2021sequence,
  title = {Offline Reinforcement Learning as One Big Sequence Modeling Problem},
  author = {Michael Janner and Qiyang Li and Sergey Levine},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2021},
}

@inproceedings{
lu2023synthetic,
title={Synthetic Experience Replay},
author={Cong Lu and Philip J. Ball and Yee Whye Teh and Jack Parker-Holder},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=6jNQ1AY1Uf}
}

@article{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21810--21823},
  year={2020}
}

@article{pearce2023imitating,
  title={Imitating human behaviour with diffusion models},
  author={Pearce, Tim and Rashid, Tabish and Kanervisto, Anssi and Bignell, Dave and Sun, Mingfei and Georgescu, Raluca and Macua, Sergio Valcarcel and Tan, Shan Zheng and Momennejad, Ida and Hofmann, Katja and others},
  journal={arXiv preprint arXiv:2301.10677},
  year={2023}
}

@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{ma2023elucidating,
  title={Elucidating The Design Space of Classifier-Guided Diffusion Generation},
  author={Ma, Jiajun and Hu, Tianyang and Wang, Wenjia and Sun, Jiacheng},
  journal={arXiv preprint arXiv:2310.11311},
  year={2023}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  publisher = {IEEE},
  title = {MuJoCo: A physics engine for model-based control.},
  url = {http://dblp.uni-trier.de/db/conf/iros/iros2012.html#TodorovET12},
  year = 2012,
  journal = {IEEE},
}

@article{nikulin2022q,
  title={Q-Ensemble for Offline RL: Don't Scale the Ensemble, Scale the Batch Size},
  author={Nikulin, Alexander and Kurenkov, Vladislav and Tarasov, Denis and Akimov, Dmitry and Kolesnikov, Sergey},
  journal={arXiv preprint arXiv:2211.11092},
  year={2022}
}
@inproceedings{bansal2023universal,
  title={Universal guidance for diffusion models},
  author={Bansal, Arpit and Chu, Hong-Min and Schwarzschild, Avi and Sengupta, Soumyadip and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={843--852},
  year={2023}
}

@misc{offinerlkit,
  author = {Yihao Sun},
  title = {OfflineRL-Kit: An Elegant PyTorch Offline Reinforcement Learning Library},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/yihaosun1124/OfflineRL-Kit}},
}

@article{agarwal2021deep,
  title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel
          and Courville, Aaron and Bellemare, Marc G},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{zhang2023learning,
  title={Learning unsupervised world models for autonomous driving via discrete diffusion},
  author={Zhang, Lunjun and Xiong, Yuwen and Yang, Ze and Casas, Sergio and Hu, Rui and Urtasun, Raquel},
  journal={arXiv preprint arXiv:2311.01017},
  year={2023}
}

@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}

@article{alonso2023diffusion,
  title={Diffusion World Models},
  author={Alonso, Eloi and Jelley, Adam and Kanervisto, Anssi and Pearce, Tim},
  year={2023}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@inproceedings{
  song2021scorebased,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=PxTIG12RRHS}
}